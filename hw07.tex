\documentclass[12pt]{article}
\usepackage{fullpage,hyperref}\setlength{\parskip}{3mm}\setlength{\parindent}{0mm}
\begin{document}

\begin{center}\bf
Homework 7. Due by 11:59pm on Sunday 10/26.

Negligence, mistakes \& how to avoid them

\end{center}
Researchers, like all other humans, make mistakes. Read pages 12--14 of {\em On Being a Scientist}.  Write brief answers to the following questions, by editing the tex file available at \url{https://github.com/ionides/810f25}, and submit the resulting pdf file via Canvas.

\begin{enumerate}

\item How should one balance the professional consequences of errors with the professional requirement to publish?
  
There may exist somewhere a perfect balance of care and speed that allows researchers to both publish frequently with no errors, but I doubt it is possible to find. In practice, I think publishing high quality papers is the most important thing, but papers should not be delayed too much for minor errors. And in practice, I think lots of people read papers with errors in them without reporting them, and it's probably important to remember that we only hear about errors that people notice. There may be lots of mistakes that happen that neither the authors nor readers are aware of, and so reproducibility is probably more important than accuracy overall.

\item What is a reasonable level of skepticism about correctness of published results?

This depends a little on what is published. On the one hand, if things are too good to be true, then maybe they are, but on the other, a paper like "Attention is All You Need" ended up being seminal work that pushed ML and AI forward by a decade. We could call the results of that paper "correct" with very little skepticism, considering the ripple effect it's had over the literature. But for minor papers that claim huge dividends based on niche methodology, perhaps it's healthy to be more skeptical since the results are easier to game, in a sense, since they are more situationally specific.
  
\item If you think you have identified an error in someone else's published paper, what are possible courses of action? What are their advantages and disadvantages?

The first and easiest is to ignore it. Depending on the severity, this is honestly what I would do. Life is too short and I don't feel comfortable correcting someone more qualified and/or credentialed than myself.

The second course is to email them directly. This gives them a chance to investigate the error, but there is a decent chance they don't do anything about it.

The third option, which should probably only be done after the second fails, is to send a notice to the journal or possibly a follow up paper demonstrating the error and disputing the findings.

\item Look on the internet in a leading statistics journal (such as Journal of the American Statistical Association and Annals of Statistics) for papers with a corrigendum, erratum or retraction. How common is it in our discipline to publish corrections of mistakes? If you find it is rare, how does the field avoid building on incorrect results?

From what I can tell in these two particular journals, it's actually quite rare (or unreported). The errors I did find seemed to be pretty minor, and the correctors were thanked for their contribution.

\item What kinds of errors arise in statistics research, and what are good research practices to avoid or reduce them?

(a) in theoretical results;

I'm unsure, but I think walking through the proof with someone else is extremely important. You need to have someone else check your logic.
    
(b) in numerical results.

Ensure reproducibility, first and foremost. I think solid testing helps, but is 
not perfect either. Wide variety of testing and simulation the should have known outputs can help as well.

\item {\bf A capstone question}. This is the last homework on the topic of responsible conduct in research and scholarship.  Here is a final RCRS question, which concerns all the classes 1--8. We have now discussed various incentives for collegial behavior and consequences for antisocial behavior, in the context of research, teaching and professional service in our field. Can you think of situations where the consequences for RCRS violations are:

  (a) Too lenient. Consequences insufficient to effectively disincentivize antisocial behavior; or too much burden of evidence required to impose consequences; or strong incentives not to impose adequate consequences.

  In practical terms, I think being able to reproduce results is one of the bigger challenges. There is so much pressure to publish, and quickly, that marginal improvements on methods get pushed with little real incentive to ensure full correctness, but also little incentive to correct them. Therefore, easy reproducibility ironically makes it easier to find errors, which benefits the community but not the individual.

  (b) Too harsh. Disproportionately damaging consequences for minor violations; or penalties imposed with too little burden of evidence; or no presumption of innocence; or incentive structures that lure people into breaking rules and then punish them for it.

  I feel that the hardest things about academia generally outside of the purview of RCRS, and following ethical guidelines is mostly pretty straightforward. The incentive structure around publication is I think the most difficult though. I don't feel that it's reasonable to have the sort of publication schedule that most universities seem to expect without the serious danger of errors, and I somewhat suspect that authors who have not had major errors found are more lucky than exceptional; though perhaps I'm overestimating how many mistakes the average person makes. My beliefs are mostly based on how I feel about my coursework and projects I've worked on in the past and my own confidence in not making errors; and so the expectation of both quantity and quality simultaneously sort of necessitates the need for risk taking and shortcuts in publication.
  
  
\end{enumerate}

\end{document}
